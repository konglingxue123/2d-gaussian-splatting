{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.morphology import medial_axis, skeletonize\n",
    "from skimage import measure\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KDTree\n",
    "from PIL import Image\n",
    "\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, dilation, disk\n",
    "from skimage.filters import median\n",
    "from skimage.morphology import binary_opening, disk\n",
    "import imgviz\n",
    "\n",
    "def colored_mask(mask, save_path=None):\n",
    "    lbl_pil = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    # print(colormap, type(colormap), colormap.flatten(), colormap.shape)\n",
    "    lbl_pil.putpalette(colormap.flatten())\n",
    "    if save_path is not None:\n",
    "        lbl_pil.save(save_path)\n",
    "\n",
    "    return lbl_pil  \n",
    "\n",
    "def show_2dpoints(pointcluster,s=None,quivers=None,qscale=1):\n",
    "    # pointcluster should be a list of numpy ndarray\n",
    "    # This functions would show a list of pint cloud in different colors\n",
    "    n = len(pointcluster)\n",
    "    nmax = n\n",
    "    if quivers is not None:\n",
    "        nq = len(quivers)\n",
    "        nmax = max(n,nq)\n",
    "    \n",
    "    colors = ['r','g','b','c','m','y','k','tomato','gold']\n",
    "    if nmax < 10:\n",
    "        colors = np.array(colors[0:nmax])\n",
    "    else: \n",
    "        colors = np.random.rand(nmax,3)\n",
    "\n",
    "    fig = plt.figure(num=1)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "    if s is None:\n",
    "        s = np.ones(n)*2\n",
    "\n",
    "    for i in range(n):\n",
    "        ax.scatter(pointcluster[i][:,0],pointcluster[i][:,1],s=s[i],c=[colors[i]],alpha=0.6)\n",
    "\n",
    "    if quivers is not None:\n",
    "        for i in range(nq):\n",
    "            ax.quiver(quivers[i][:,0],quivers[i][:,1],quivers[i][:,2],quivers[i][:,3],color=[colors[i]],scale=qscale)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def SVD(points):\n",
    "    # 二维，三维均适用\n",
    "    # 二维直线，三维平面\n",
    "    pts = points.copy()\n",
    "    # 奇异值分解\n",
    "    c = np.mean(pts, axis=0)\n",
    "    A = pts - c # shift the points\n",
    "    A = A.T #3*n\n",
    "    u, s, vh = np.linalg.svd(A, full_matrices=False, compute_uv=True) # A=u*s*vh\n",
    "    normal = u[:,-1]\n",
    "\n",
    "    # 法向量归一化\n",
    "    nlen = np.sqrt(np.dot(normal,normal))\n",
    "    normal = normal / nlen\n",
    "    # normal 是主方向的方向向量 与PCA最小特征值对应的特征向量是垂直关系\n",
    "    # u 每一列是一个方向\n",
    "    # s 是对应的特征值\n",
    "    # c >>> 点的中心\n",
    "    # normal >>> 拟合的方向向量\n",
    "    return u,s,c,normal\n",
    "\n",
    "\n",
    "def calcu_dis_from_ctrlpts(ctrlpts):\n",
    "    if ctrlpts.shape[1]==4:\n",
    "        return np.sqrt(np.sum((ctrlpts[:,0:2]-ctrlpts[:,2:4])**2,axis=1))\n",
    "    else:\n",
    "        return np.sqrt(np.sum((ctrlpts[:,[0,2]]-ctrlpts[:,[3,5]])**2,axis=1))\n",
    "\n",
    "\n",
    "def estimate_normal_for_pos(pos,points,n):\n",
    "    \"\"\"\n",
    "    计算pos处的法向量.\n",
    "    \n",
    "    Input：\n",
    "    ------\n",
    "    pos: nx2 ndarray 需要计算法向量的位置.\n",
    "    points: 骨架线的点集\n",
    "    n: 用到的近邻点的个数\n",
    "    \n",
    "    Output：\n",
    "    ------\n",
    "    normals: nx2 ndarray 在pos位置处的法向量.\n",
    "    \"\"\"\n",
    "    \n",
    "    # estimate normal vectors at a given point\n",
    "    pts = np.copy(points)\n",
    "    tree = KDTree(pts, leaf_size=2)\n",
    "    idx = tree.query(pos, k=n, return_distance=False, dualtree=False, breadth_first=False)\n",
    "    #pts = np.concatenate((np.concatenate((pts[0].reshape(1,-1),pts),axis=0),pts[-1].reshape(1,-1)),axis=0)\n",
    "    normals = []\n",
    "    for i in range(0,pos.shape[0]):\n",
    "        pts_for_normals = pts[idx[i,:],:]\n",
    "        _,_,_,normal = SVD(pts_for_normals)\n",
    "        normals.append(normal)\n",
    "    normals = np.array(normals)\n",
    "    return normals\n",
    "\n",
    "\n",
    "def estimate_normals(points,n):\n",
    "    \"\"\"\n",
    "    计算points表示的曲线上的每一个点法向量.\n",
    "    等同于 estimate_normal_for_pos(points,points,n)\n",
    "\n",
    "    Input：\n",
    "    ------\n",
    "    points: nx2 ndarray 曲线点集.\n",
    "    n: 用到的近邻点的个数\n",
    "    \n",
    "    Output：\n",
    "    ------\n",
    "    normals: nx2 ndarray 在points曲线上的每一处的法向量.\n",
    "    \"\"\"\n",
    "    \n",
    "    pts = np.copy(points)\n",
    "    tree = KDTree(pts, leaf_size=2)\n",
    "    idx = tree.query(pts, k=n, return_distance=False, dualtree=False, breadth_first=False)\n",
    "    #pts = np.concatenate((np.concatenate((pts[0].reshape(1,-1),pts),axis=0),pts[-1].reshape(1,-1)),axis=0)\n",
    "    normals = []\n",
    "    for i in range(0,pts.shape[0]):\n",
    "        pts_for_normals = pts[idx[i,:],:]\n",
    "        _,_,_,normal = SVD(pts_for_normals)\n",
    "        normals.append(normal)\n",
    "    normals = np.array(normals)\n",
    "    return normals\n",
    "\n",
    "def get_crack_ctrlpts(centers,normals,bpoints,hband=5,vband=2,est_width=0):\n",
    "    # main algorithm to obtain crack width\n",
    "    cpoints = np.copy(centers)\n",
    "    cnormals = np.copy(normals)\n",
    "\n",
    "    xmatrix = np.array([[0,1],[-1,0]])\n",
    "    cnormalsx = np.dot(xmatrix,cnormals.T).T # the normal of x axis\n",
    "    N = cpoints.shape[0]\n",
    "\n",
    "    bpixel_and_skeleton = []\n",
    "    widths = []\n",
    "    for i in range(N):\n",
    "        try:\n",
    "            ny = cnormals[i]\n",
    "            nx = cnormalsx[i]\n",
    "            tform = np.array([nx,ny])\n",
    "            bpoints_loc = np.dot(tform,bpoints.T).T\n",
    "            cpoints_loc = np.dot(tform,cpoints.T).T\n",
    "            ci = cpoints_loc[i]\n",
    "\n",
    "            bl_ind = (bpoints_loc[:,0]-(ci[0]-hband))*(bpoints_loc[:,0]-ci[0])<0\n",
    "            br_ind = (bpoints_loc[:,0]-ci[0])*(bpoints_loc[:,0]-(ci[0]+hband))<=0\n",
    "            bl = bpoints_loc[bl_ind] # left points\n",
    "            br = bpoints_loc[br_ind] # right points\n",
    "\n",
    "            if est_width>0:\n",
    "                # 下面的数值 est_width 是预估计的裂缝宽度\n",
    "                half_est_width = est_width / 2\n",
    "                blt = bl[(bl[:,1]-(ci[1]+half_est_width))*(bl[:,1]-ci[1])<0]\n",
    "                blb = bl[(bl[:,1]-(ci[1]-half_est_width))*(bl[:,1]-ci[1])<0]\n",
    "                brt = br[(br[:,1]-(ci[1]+half_est_width))*(br[:,1]-ci[1])<0]\n",
    "                brb = br[(br[:,1]-(ci[1]-half_est_width))*(br[:,1]-ci[1])<0]\n",
    "            else:\n",
    "                blt = bl[bl[:,1]>np.mean(bl[:,1])]\n",
    "                if np.ptp(blt[:,1])>vband:\n",
    "                    blt = blt[blt[:,1]>np.mean(blt[:,1])]\n",
    "\n",
    "                blb = bl[bl[:,1]<np.mean(bl[:,1])]\n",
    "                if np.ptp(blb[:,1])>vband:\n",
    "                    blb = blb[blb[:,1]<np.mean(blb[:,1])]\n",
    "\n",
    "                brt = br[br[:,1]>np.mean(br[:,1])]\n",
    "                if np.ptp(brt[:,1])>vband:\n",
    "                    brt = brt[brt[:,1]>np.mean(brt[:,1])]\n",
    "\n",
    "                brb = br[br[:,1]<np.mean(br[:,1])]\n",
    "                if np.ptp(brb[:,1])>vband:\n",
    "                    brb = brb[brb[:,1]<np.mean(brb[:,1])]\n",
    "\n",
    "                # blt = bl[bl[:,1]>np.mean(bl[:,1])]\n",
    "                # if np.ptp(blt[:,1])>vband:\n",
    "                #    blt = blt[blt[:,1]<ci[1]+50]\n",
    "                #    #blt = blt[blt[:,1]>np.mean(blt[:,1])] （外侧）\n",
    "                #    #blt = blt[blt[:,1]<(np.max(blt[:,1])-0.5*np.ptp(blt[:,1]))] （内侧）\n",
    "\n",
    "                # blb = bl[bl[:,1]<np.mean(bl[:,1])]\n",
    "                # if np.ptp(blb[:,1])>vband:\n",
    "                #    blb = blb[blb[:,1]>ci[1]-50]\n",
    "                #    #blb = blb[blb[:,1]<np.mean(blb[:,1])]\n",
    "                #    #blb = blb[blb[:,1]>(np.min(blb[:,1])+0.5*np.ptp(blb[:,1]))]\n",
    "\n",
    "                # brt = br[br[:,1]>np.mean(br[:,1])]\n",
    "                # if np.ptp(brt[:,1])>vband:\n",
    "                #    brt = brt[brt[:,1]<ci[1]+50]\n",
    "                #    #brt = brt[brt[:,1]>np.mean(brt[:,1])]\n",
    "                #    #brt = brt[brt[:,1]<(np.max(brt[:,1])-0.5*np.ptp(brt[:,1]))]\n",
    "\n",
    "                # brb = br[br[:,1]<np.mean(br[:,1])]\n",
    "                # if np.ptp(brb[:,1])>vband:\n",
    "                #    brb = brb[brb[:,1]>ci[1]-50]\n",
    "                #    # brb = brb[brb[:,1]<np.mean(brb[:,1])]\n",
    "                #    # brb = brb[brb[:,1]>(np.min(brb[:,1])+0.5*np.ptp(brb[:,1]))]\n",
    "\n",
    "            #bh = np.vstack((bl,br))\n",
    "            #bmax = np.max(bh[:,1])\n",
    "            #bmin = np.min(bh[:,1])\n",
    "\n",
    "            #blt = bl[bl[:,1]>bmax-vband] # left top points\n",
    "            #blb = bl[bl[:,1]<bmin+vband] # left bottom points\n",
    "\n",
    "            #brt = br[br[:,1]>bmax-vband] # right top points\n",
    "            #brb = br[br[:,1]<bmin+vband] # right bottom points\n",
    "\n",
    "\n",
    "            t1 = blt[np.argsort(blt[:,0])[-1]]\n",
    "            t2 = brt[np.argsort(brt[:,0])[0]]\n",
    "\n",
    "            b1 = blb[np.argsort(blb[:,0])[-1]]\n",
    "            b2 = brb[np.argsort(brb[:,0])[0]]\n",
    "\n",
    "\n",
    "            interp1 = (ci[0]-t1[0])*((t2[1]-t1[1])/(t2[0]-t1[0]))+t1[1]\n",
    "            interp2 = (ci[0]-b1[0])*((b2[1]-b1[1])/(b2[0]-b1[0]))+b1[1]\n",
    "\n",
    "            if interp1-ci[1]>0 and interp2-ci[1]<0:\n",
    "                widths.append([i,interp1-ci[1],interp2-ci[1]])\n",
    "\n",
    "                interps = np.array([[ci[0],interp1],[ci[0],interp2]])\n",
    "\n",
    "                interps_rec = np.dot(np.linalg.inv(tform),interps.T).T\n",
    "\n",
    "                #show_2dpoints([bpointsxl_loc1,bpointsxl_loc2,bpointsxr_loc1,bpointsxr_loc2,np.array([ptsl_1,ptsl_2]),np.array([ptsr_1,ptsr_2]),interps,ci.reshape(1,-1)],s=[1,1,1,1,20,20,20,20])\n",
    "                interps_rec = interps_rec.reshape(1,-1)[0,:]\n",
    "                bpixel_and_skeleton.append(interps_rec)\n",
    "        except:\n",
    "            print(\"the %d-th was wrong\" % i)\n",
    "            continue\n",
    "    bpixel_and_skeleton = np.array(bpixel_and_skeleton)\n",
    "    widths = np.array(widths)\n",
    "    # check\n",
    "    # show_2dpoints([np.array([[ci[0],interp1],[ci[0],interp2]]),np.array([t1,t2,b1,b2]),cpoints_loc,bl,br],[10,20,15,2,2])\n",
    "    return bpixel_and_skeleton, widths\n",
    "\n",
    "######################################################\n",
    "if __name__ == '__main__':\n",
    "    import cv2\n",
    "    img_name = '0032'\n",
    "    # mask_dir = '/home/ubunto/Project/konglx/pcd/2dgs/2d-gaussian-splatting-main/tools/boundary_0032_medial_axis_cls_num_all.png'\n",
    "    path = f'/home/ubunto/Project/konglx/pcd/2dgs/2d-gaussian-splatting-main/datasets/dalian_xinghaiwandaqiao_video_input_rgb/outputs/labelme_outputs/SegmentationClass/{img_name}.png'\n",
    "    # path = '/home/ubunto/Project/konglx/pcd/2dgs/2d-gaussian-splatting-main/output/projection/CFD_044.jpg'\n",
    "    # path = '/home/ubunto/图片/2025-06-13_15-51.png'\n",
    "\n",
    "\n",
    "    # image = io.imread(path, as_gray=True)\n",
    "    # image_pil = Image.open(path).convert('1')\n",
    "    # image = np.array(image_pil)\n",
    "\n",
    "    # 用此方法读取图片，可以自动判断图片的模式，并将其转化为0-1的灰度图\n",
    "    def judge_image_mode(path):\n",
    "        img_pil = Image.open(path)\n",
    "        img = np.array(img_pil)\n",
    "\n",
    "        # 根据读取的mask的信息，判断后续操作（有的mask数值取值范围为0-1，有的取值范围为0-255）\n",
    "        if np.max(img) == 255:\n",
    "            img_pil = Image.open(path).convert('1')\n",
    "            img = np.array(img_pil)\n",
    "        else:\n",
    "            img_pil = Image.open(path)\n",
    "            img = np.array(img_pil)\n",
    "        return img_pil, img\n",
    "\n",
    "    image_pil, image = judge_image_mode(path)\n",
    "    print('####### np.unique(image) #######', np.unique(image))\n",
    "    # image中不为1的地方为背景，为1的地方为前景\n",
    "    # image[image!= True] = 0\n",
    "    # image[image == True] = 255\n",
    "    cls_num_list = np.unique(image).tolist()\n",
    "    cls_num_list.remove(0)\n",
    "    print('####### cls_num_list #######', cls_num_list)\n",
    "    \n",
    "    \n",
    "    cls_num_mask_dict = {}\n",
    "    cls_num_skel_dict = {}  # 每个类别的每个骨架\n",
    "    cls_num_skel_all_dict = {} # 每个类别的骨架相加\n",
    "    \n",
    "    cls_num_edge_to_calculate_mid_axis_dict = {} # 每个类别的边界点\n",
    "    cls_num_skel_calculate_mid_axis_dict = {} # 每个类别的骨架的中轴线\n",
    "    cls_num_edge_pair_dict = {} # 每个类别的边界点对\n",
    "    \n",
    "    for cls_num in cls_num_list:\n",
    "        print(f\"############ cls_num #############: {cls_num}\")\n",
    "        cls_num_mask_dict[cls_num] = []\n",
    "        cls_num_skel_dict[cls_num] = []\n",
    "        cls_num_skel_all_dict[cls_num] = []\n",
    "        \n",
    "        cls_num_edge_to_calculate_mid_axis_dict[cls_num] = []\n",
    "        cls_num_skel_calculate_mid_axis_dict[cls_num] = []\n",
    "        cls_num_edge_pair_dict[cls_num] = []\n",
    "        \n",
    "        cls_num_mask = image.copy()\n",
    "        cls_num_mask[cls_num_mask != cls_num] = 0\n",
    "        \n",
    "        num_labels, labels = cv2.connectedComponents(cls_num_mask)\n",
    "        print(f\"连通区域的个数(包含背景)为: {num_labels}\")\n",
    "        print(f\"连通区域的标签为: {labels.shape}\", np.unique(labels))   \n",
    "        # 统计mask的个数（减去背景）\n",
    "        mask_count = num_labels - 1\n",
    "        \n",
    "        print(f\"mask的个数(含有少量孤立点)为: {mask_count}\")\n",
    "        \n",
    "        less_than_10_mask_count = []\n",
    "        # 为每个mask编号（从1开始，因为0通常代表背景）\n",
    "        ############################# 基于语义分类的实例分类 ################################\n",
    "        for num_label in range(1, num_labels):\n",
    "            # single_mask = np.uint8(labels == label) * 255\n",
    "            # single_mask 分别代表不同label的mask,保持与原label数值一致\n",
    "            single_mask = np.zeros(cls_num_mask.shape, dtype=np.uint8)\n",
    "            single_mask[labels == num_label] = num_label\n",
    "            \n",
    "            single_mask_pil = colored_mask(single_mask)\n",
    "            single_mask = np.array(single_mask_pil)\n",
    "            \n",
    "            print('np.unique(single_mask):', np.unique(single_mask))\n",
    "            # 计算single_mask的非零的数量\n",
    "            non_zero_count = np.count_nonzero(single_mask)\n",
    "            # print(f\"mask={label}的非零的数量为: {non_zero_count}\")\n",
    "            if non_zero_count < 10:\n",
    "                less_than_10_mask_count.append(num_label)\n",
    "                mask_count -= 1\n",
    "                # single_mask[labels == label] = label\n",
    "                # print('更新后的np.unique(single_mask):', np.unique(single_mask))\n",
    "                continue \n",
    "            else:\n",
    "                single_mask_new = single_mask.copy()\n",
    "                cls_num_mask_dict[cls_num].append(single_mask_new)\n",
    "                print('single_mask_new.shape:', single_mask_new.shape, np.unique(single_mask_new))\n",
    "            # 这里可以对单个mask进行进一步处理，比如保存图像\n",
    "            # cv2.imwrite(f'mask_{label}.png', single_mask)\n",
    "            # cv2.imshow(f'mask_{label}', single_mask)\n",
    "            # cv2.waitKey(0)\n",
    "            plt.title(f'mask class is {cls_num}, number id is {num_label}')\n",
    "            plt.imshow(single_mask_pil)\n",
    "            # single_mask_pil.save(f'mask_{label}.png')\n",
    "            plt.show()\n",
    "            \n",
    "            # 每个单独的损伤label的骨架提取计算最大宽度\n",
    "            single_mask_new_copy = single_mask.copy()\n",
    "            # if type(cls_num) == int:\n",
    "            single_mask_new_copy[single_mask_new_copy!= num_label] = 0\n",
    "            single_mask_new_copy[single_mask_new_copy == num_label] = 255\n",
    "            \n",
    "            img_pil_new = Image.fromarray(single_mask_new_copy)\n",
    "    \n",
    "    # image[image!= 0] = 255\n",
    "    # image[image == 0] = 0\n",
    "    \n",
    "            img_pil_new = Image.fromarray(single_mask_new_copy)\n",
    "            image_pil = img_pil_new.convert('1')\n",
    "            image_np = np.array(image_pil)\n",
    "            print(image_np.shape)\n",
    "            iw,ih = image_np.shape\n",
    "\n",
    "            blobs  = np.copy(image_np)\n",
    "            # blobs[blobs<128] = 0\n",
    "            # blobs[blobs>128] = 1\n",
    "\n",
    "            blobs = blobs.astype(np.uint8)\n",
    "            # Generate the data\n",
    "            #blobs = data.binary_blobs(200, blob_size_fraction=.2,\n",
    "                                    #volume_fraction=.35, seed=1)\n",
    "            # using scikit-image\n",
    "            ## Compute the medial axis (skeleton) and the distance transform\n",
    "            #skel, distance = medial_axis(blobs, return_distance=True)\n",
    "            ## Distance to the background for pixels of the skeleton\n",
    "            #dist_on_skel = distance * skel\n",
    "\n",
    "            # Compare with other skeletonization algorithms\n",
    "            print(blobs)\n",
    "            skeleton_org = skeletonize(blobs, method='lee')\n",
    "            # 去除skeleton的多余分支\n",
    "            labeled = label(skeleton_org)\n",
    "            regions = regionprops(labeled)\n",
    "            min_length = 1  # 设定最小分支长度\n",
    "\n",
    "            mask = np.zeros_like(skeleton_org, dtype=bool)\n",
    "            for reg in regions:\n",
    "                if reg.area >= min_length:\n",
    "                    mask[reg.coords[:, 0], reg.coords[:, 1]] = True\n",
    "            skeleton = mask.astype(np.uint8)\n",
    "            # skeleton = skeleton_org\n",
    "            \n",
    "            \n",
    "            # skeleton = skeletonize(blobs)\n",
    "            print(\"########### skeleton.shape ###########\", skeleton.shape, np.unique(skeleton), skeleton.dtype)\n",
    "            if skeleton.dtype == np.uint8:\n",
    "                skeleton = skeleton.astype(np.bool_)\n",
    "\n",
    "            # skeleton_lee = skeletonize(blobs, method='lee')\n",
    "            x, y = np.where(skeleton>0)\n",
    "            centers = np.hstack((x.reshape(-1,1),y.reshape(-1,1)))\n",
    "            print('centers.shape', centers.shape)\n",
    "\n",
    "            normals = estimate_normals(centers, 9) # 这个用于估计法向量的KNN\n",
    "\n",
    "            # search contours of the crack\n",
    "            contours = measure.find_contours(blobs, 0.8)\n",
    "            print('len(contours)', len(contours))\n",
    "            # print(contours[0].shape, contours[1].shape) \n",
    "            # bl = contours[0]\n",
    "            # br = contours[1]\n",
    "\n",
    "            # bpoints = np.vstack((bl,br))\n",
    "            bpoints = np.concatenate(contours,axis=0)\n",
    "            print('bpoints.shape', bpoints.shape)\n",
    "\n",
    "            #bpixel_and_skeleton, widths = get_crack_ctrlpts(centers,normals,bpoints,hband=2,vband=2)\n",
    "\n",
    "\n",
    "            bpixel = np.zeros((iw,ih,3),dtype=np.uint8)\n",
    "            bpoints = bpoints.astype(np.int64)\n",
    "            bpixel[bpoints[:,0],bpoints[:,1],0] = 255\n",
    "\n",
    "            skeleton_pixel = np.zeros((iw,ih,3),dtype=np.uint8)\n",
    "            skeleton_pixel[skeleton,1] = 255\n",
    "\n",
    "            bpixel_and_skeleton = np.copy(bpixel)\n",
    "            bpixel_and_skeleton[skeleton,1] = 255\n",
    "\n",
    "\n",
    "            fig, axes = plt.subplots(2,2, figsize=(30, 15))\n",
    "            ax = axes.ravel()\n",
    "\n",
    "            ax[0].imshow(blobs, cmap=plt.cm.gray)\n",
    "            ax[0].axis('off')\n",
    "\n",
    "\n",
    "            ax[1].imshow(bpixel_and_skeleton)\n",
    "            #for contour in contours:\n",
    "            #    ax[1].plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "\n",
    "            # for n, contour in enumerate(contours):\n",
    "            #     ax[1].plot(contour[:, 1], contour[:, 0], linewidth=1, color='red')\n",
    "            #ax[1].set_title('medial_axis')\n",
    "            ax[1].axis('off')\n",
    "\n",
    "\n",
    "            ax[2].imshow(bpixel_and_skeleton)\n",
    "            interps, widths = get_crack_ctrlpts(centers, normals, bpoints, hband=2, vband=2, est_width=100)\n",
    "            print('interps.shape, widths.shape', interps.shape, widths.shape)\n",
    "            # 如果interps的x\n",
    "            # interps_center\n",
    "            # print(np.random.choice(interps.shape[0], interps.shape[0]), len(np.random.choice(interps.shape[0], interps.shape[0])))\n",
    "            # print(interps)\n",
    "            # 计算interps连线和skeleton的交点\n",
    "            # interps_center = []\n",
    "            # for i in range(interps.shape[0]):\n",
    "            #     interps_center.append(np.mean(np.vstack((interps[i,:2],interps[i,2:]),axis=0),axis=0))\n",
    "            interps_center_x = interps[:, [0,2]].mean(axis=1)\n",
    "            interps_center_y = interps[:, [1,3]].mean(axis=1)\n",
    "            interps_center = np.hstack((interps_center_x.reshape(-1,1),interps_center_y.reshape(-1,1)))\n",
    "            # interps_center_x_ls = []\n",
    "            # interps_center_y_ls = []\n",
    "            # for i in range(interps.shape[0]):\n",
    "            #     interps_center_x_ls.append((interps[i,1]+interps[i,3])/2)\n",
    "            #     interps_center_y_ls.append((interps[i,0]+interps[i,2])/2)\n",
    "            # interps_center_x = np.array(interps_center_x_ls)\n",
    "            # interps_center_y = np.array(interps_center_y_ls)\n",
    "            interps_center = np.hstack((interps_center_x.reshape(-1,1),interps_center_y.reshape(-1,1)))\n",
    "            # 每隔5个选取interps_center的点\n",
    "            inter_num = 5\n",
    "            interps_center_show = interps_center[::inter_num,:]\n",
    "            # for i in range(0,interps_center_show.shape[0],5):\n",
    "            \n",
    "            print('interps_center.shape', interps_center.shape)\n",
    "            \n",
    "            # for i in range(interps.shape[0]):\n",
    "            #     interps\n",
    "            \n",
    "            # interps_show = interps[np.random.choice(interps.shape[0], 120, replace=False),:] # 由于太多，这里随机采样120个测量位置，进行显示\n",
    "            # 在interps中每隔5个选取interps_show的点\n",
    "            interps_show = interps[::inter_num,:]\n",
    "            # for i in range(0,interps_show.shape[0],5):\n",
    "            #     ax[2].plot([interps_show[i,1],interps_show[i,3]],[interps_show[i,0],interps_show[i,2]],c='c',ls='-',lw=1,marker='o',ms=1,mec='c',mfc='c')\n",
    "            # interps_show = interps[np.random.choice(interps.shape[0], interps.shape[0]),:] # 由于太多，这里随机采样120个测量位置，进行显示\n",
    "            for i in range(interps_show.shape[0]):\n",
    "                ax[2].plot([interps_show[i,1],interps_show[i,3]],[interps_show[i,0],interps_show[i,2]],c='c', ls='-', lw=1, marker='o',ms=1,mec='c',mfc='c')\n",
    "            \n",
    "            print('########### interps_show.shape ###########', interps_show.shape)\n",
    "\n",
    "\n",
    "            \n",
    "            ax[3].imshow(bpixel_and_skeleton)\n",
    "            # ax[3]绘制测量点\n",
    "            ax[3].plot(interps_center_show[:,1],interps_center_show[:,0],c='w',marker='o',ms=3, linestyle='')\n",
    "            # ax[3].plot(interps_center[:,1],interps_center[:,0],c='c')\n",
    "            ax[3].set_title('crack width estimation')\n",
    "\n",
    "            widths_show = widths[::inter_num,:]\n",
    "            print('widths_show.shape', widths_show.shape)\n",
    "            print('interps_center_show.shape', interps_center_show.shape)\n",
    "\n",
    "            ## ================ small window ==================\n",
    "            #pos = np.array([191, 291]).reshape(1,-1) # input (x,y) where need to calculate crack width\n",
    "            ## pos = np.array([142, 178]).reshape(1,-1)\n",
    "\n",
    "            #posn = estimate_normal_for_pos(pos,centers,3)\n",
    "\n",
    "            #interps, widths2 = get_crack_ctrlpts(pos,posn,bpoints,hband=1.5,vband=2)\n",
    "\n",
    "\n",
    "            #sx = pos[0,0] - 20\n",
    "            #sy = pos[0,1] - 20\n",
    "\n",
    "            #ax[2].imshow(bpixel_and_skeleton)\n",
    "\n",
    "            #for i in range(interps.shape[0]):\n",
    "            #    ax[2].plot([interps[i,1],interps[i,3]],[interps[i,0],interps[i,2]],c='c',ls='-',lw=5,marker='o',ms=8,mec='c',mfc='c')\n",
    "\n",
    "            #ax[2].set_ylim(sx,sx+40)\n",
    "            #ax[2].set_xlim(sy,sy+40)\n",
    "\n",
    "            ##ax[2].set_title('skeletonize')\n",
    "            #ax[2].axis('off')\n",
    "\n",
    "            #print(interps)\n",
    "            \n",
    "            cls_num_skel_all_dict[cls_num].append(skeleton)\n",
    "            \n",
    "            cls_num_skel_calculate_mid_axis_dict[cls_num].append(interps_center)\n",
    "            cls_num_edge_to_calculate_mid_axis_dict[cls_num].append(bpoints)\n",
    "            cls_num_edge_pair_dict[cls_num].append(interps)\n",
    "            \n",
    "            \n",
    "            fig.tight_layout()\n",
    "            fig.savefig(f'crack_width_estimation_{img_name}.png', dpi=300)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "import os\n",
    "save_dir = '/home/ubunto/Project/konglx/pcd/2dgs/2d-gaussian-splatting-main/output/dalian_xinghaiwandaqiao_rgb/img_point_width'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(save_dir, 'cls_num_edge_pair_dict.npy'), cls_num_edge_pair_dict)\n",
    "np.save(os.path.join(save_dir, 'cls_num_edge_to_calculate_mid_axis_dict.npy'), cls_num_edge_to_calculate_mid_axis_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dgs_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
